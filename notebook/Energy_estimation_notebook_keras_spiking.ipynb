{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worse-corrections",
   "metadata": {},
   "source": [
    "## 0 - Setting CUDA VISIBLE DEVICES and importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-hobby",
   "metadata": {},
   "source": [
    "Selecting the GPUs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-dance",
   "metadata": {},
   "source": [
    "Importing packages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "from utils import add_temporal_dim\n",
    "import create_models\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers\n",
    "from notebook_utils import extract_dataset, extract_model_info, energy_estimation\n",
    "from utils import COLOUR_DICTIONARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-antique",
   "metadata": {},
   "source": [
    "## 2 - Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps=10 #Number of timesteps\n",
    "dt=0.1 # [s] - Timestep size\n",
    "n_test_images=10 # Number of images used for energy estimation\n",
    "train_percentage=0.8 # Percentage of train dataset over the entire images\n",
    "test_percentage=0.15 #Percentage of test dataset over the entire images (Note: valid_percentage=1-(train_percentage+test_percentage))\n",
    "notebook_verbose=False #If true, all the notebook is executed in verbose mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-necessity",
   "metadata": {},
   "source": [
    "## 3 - Creating a spiking model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-charm",
   "metadata": {},
   "source": [
    "Loading a pretrained Spiking VGG16 model pretrained on ImageNet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_models.create_spiking_vgg16_model('', input_shape=(64, 64, 3), num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-lawrence",
   "metadata": {},
   "source": [
    "Showing model summary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "if notebook_verbose:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-keeping",
   "metadata": {},
   "source": [
    "## 4 - Extracting and formatting EuroSAT datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-herald",
   "metadata": {},
   "source": [
    "Extracting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_ds, valid_ds, test_ds] = extract_dataset(dataset_path=\"../datasets/EuroSAT\", train_percentage=train_percentage, test_percentage=test_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds =train_ds.take(n_test_images) #Limiting the number of images to n_test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-relationship",
   "metadata": {},
   "source": [
    "Reshaping dataset in time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t = train_ds.map(add_temporal_dim(timesteps=n_timesteps), num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-regression",
   "metadata": {},
   "source": [
    "## 5 - Calculating model energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-court",
   "metadata": {},
   "source": [
    "Energy estimation for artificial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_synop_energy, artificial_neuron_energy=energy_estimation(model, x_test_t=None, spiking_model=False, device_list=['cpu','gpu', 'arm','myriad2','loihi', 'spinnaker','spinnaker2'], n_timesteps=n_timesteps, dt=dt, verbose=notebook_verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-nevada",
   "metadata": {},
   "source": [
    "Energy estimation for spiking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "spiking_synop_energy, spiking_neuron_energy=energy_estimation(model, x_test_t=x_train_t, spiking_model=True, device_list=['loihi', 'spinnaker','spinnaker2'], n_timesteps=n_timesteps, dt=dt, verbose=notebook_verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-wound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
