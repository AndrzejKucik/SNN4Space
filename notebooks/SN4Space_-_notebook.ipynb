{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5331140",
   "metadata": {},
   "source": [
    "# Spiking Neural Networks for Land Cover and Land Use Classification\n",
    "This notebook is a tutorial on how to reproduce the results from [A. Kucik, G. Meoni, *Investigating Spiking Neural Networks for Energy-Efficient On-Board AI Applications. A Case Study in Land Cover and Land Use Classification\n",
    "*](https://ieeexplore.ieee.org/document/9522999). It will guide you through artificial neural network (ANN) training, spi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d74161",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "This notebook uses [Python](https://www.python.org/) 3.10 and requires the following third-party libraries libraries (with their recommended versions indicated):\n",
    "* [KerasSpiking](https://www.nengo.ai/keras-spiking/) 0.3.0\n",
    "* [NumPy](https://numpy.org/) 1.19.5\n",
    "* [TensorFlow](https://www.tensorflow.org/) 2.6.2\n",
    "* [TensorFlow Datasets](https://www.tensorflow.org/datasets) 4.5.0\n",
    "* [Tensorflow I/O](https://www.tensorflow.org/io) 0.21.0\n",
    "\n",
    "We recommend that you create a separate environment for this project. These packages can be installed via `pip` or `conda` outside of this notebook or, alternatively, you can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install numpy==1.19.5 \n",
    "!{sys.executable} -m pip install tensorflow==2.6.2 tensorflow-datasets==4.5.0  tensorflow-io==0.21.0\n",
    "!{sys.executable} -m pip install keras-spiking==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be814c1",
   "metadata": {},
   "source": [
    "In case there are issues with running the [TensorFlow](https://www.tensorflow.org/) files on a GPU-equipped workstation, we recommend trying [TensorFlow](https://www.tensorflow.org/)\n",
    "nightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "!{sys.executable} -m pip install tf-nightly tensorflow-nightly-io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aaa4b9",
   "metadata": {},
   "source": [
    "## Imports and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6b3bc",
   "metadata": {},
   "source": [
    "Let us import all the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Built-in modules -- #\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# -- Third-party modules -- #\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# -- Proprietary modules -- #\n",
    "from auxiliary import plot_energy\n",
    "from create_models import create_vgg16_model, create_spiking_vgg16_model\n",
    "from dataloaders import load_data\n",
    "from energy_estimations import energy_estimation\n",
    "from utils import colour_str, DTStop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706919e",
   "metadata": {},
   "source": [
    "We also set the hyperparameters. They are defined as follows:\n",
    "\n",
    "1. Dataset parameters\n",
    "    * `DATASET` - chosen dataset; either `eurosat`, or `ucm`; one can also add  either `prewitt` or `sobel`, then the (normalised) Prewitt or Sobel transforms are applied to the input images, and  also, optionally `mask`, then the original images with those pixels, for  which the Prewitt or Sobel transform are zero, masked out are used as the input; if `sq` is added, then the transforms are squared (or, equivalently, the square root in the Prewitt or  obel transforms is not applied); so for example it can be `eurosat_prewitt_sq_mask` ot `ucm_sobel` etc.\n",
    "  \n",
    "2. ANN training parameters\n",
    "    * `ANN_EPOCHS` - number of training epochs,\n",
    "    * `ANN_BATCH_SIZE` - training batch size (per a replica),\n",
    "    * `ANN_LEARNING_RATE`- learning rate,\n",
    "    * `KERNEL_L2` - regularization L<sub>2</sub> parameter for the convolutional kernels,\n",
    "    * `BIAS_L1` - regularization L<sub>1</sub> parameter for the convolutional biases,\n",
    "\n",
    "3. SNN training parameters\n",
    "    * `SNN_EPOCHS` - (starting) number of training epochs,\n",
    "    * `SNN_BATCH_SIZE` - (starting) training batch size (per a replica),\n",
    "    * `SNN_LEARNING_RATE`- (starting) learning rate,\n",
    "    * `ITERATE` - boolean determining whether the training should be performed iteratively, doubling the number of timesteps, and halving the batch size, the number of epochs, and the learning rate at each iteration,\n",
    "    * `TIMESTEPS` - number of the simulation timesteps,\n",
    "    * `DT` - temporal resolution of timesteps; it is decreased during the training until it reaches the value of 1 ms (`DT_TARGET`),\n",
    "    * `L2` - weight penalty for L<sub>2</sub> activity regularization of the spikes,\n",
    "    * `LOWER_HZ` - lower frequency threshold for spiking rate regularization,\n",
    "    * `UPPER_HZ` - upper frequency threshold for spiking rate regularization,\n",
    "    * `TAU` - tau parameter for the low-pass filter.\n",
    "\n",
    "4. Augmentation parameters \n",
    "    * `LOWER_ZOOM` - augmentation parameter; lower bound for a random zoom factor; must be positive,\n",
    "    * `UPPER_ZOOM` - augmentation parameter; upper bound for a random zoom factor; must be bigger than `LOWER_ZOOM`.\n",
    "    * `MAX_BRIGHTNESS_DELTA` - augmentation parameter; maximum brightness delta; must be a non-negative float,\n",
    "    * `MAX_HUE_DELTA` - augmentation parameter; maximum hue delta; must be in the interval \\[0, 0.5\\],\n",
    "    * `LOWER_CONTRAST` - augmentation parameter; lower bound for a random contrast factor; must be positive,\n",
    "    * `UPPER_CONTRAST` - augmentation parameter; upper bound for a random contrast factor must be bigger than  LOWER_CONTRAST`,\n",
    "    * `LOWER_SATURATION` - augmentation parameter; lower bound for a random saturation factor; must be positive,\n",
    "    * `UPPER_SATURATION` - augmentation parameter; upper bound for a random saturation factor; must be bigger than `LOWER_SATURATION`.\n",
    "\n",
    "5. Save paths\n",
    "    * `ANN_MODEL_PATH` - path to where the trained ANN model is saved (if we want to avoid retraining) or will be saved (after training),\n",
    "    * `SNN_MODELS_PATH` - path to where the trained SNN model is saved (if we want to avoid retraining) or will be saved (after training),\n",
    "\n",
    "The default values of these parameters are the ones that empirically gave us the best test accuracy performance (91.43%) on [UC Merced](http://weegee.vision.ucmerced.edu/datasets/landuse.html) and (95.07%) on [EuroSat](https://github.com/phelber/EuroSAT) for the artificial neural network. But feel free to modify them if you want to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Dataset parameters\n",
    "DATASET = 'eurosat'\n",
    "INPUT_SHAPE = (224, 224, 3) if 'ucm' in DATASET.lower() else (64, 64, 3)\n",
    "NUM_CLASSES = 21 if 'ucm' in DATASET.lower() else 10\n",
    "\n",
    "# - ANN training parameters\n",
    "ANN_EPOCHS = 1000\n",
    "ANN_BATCH_PER_REPLICA = 32\n",
    "ANN_LR = .001\n",
    "KERNEL_L2 = 1e-4\n",
    "BIAS_L1 = 1e-5\n",
    "\n",
    "# - SNN training parameters\n",
    "SNN_EPOCHS = 16\n",
    "SNN_BATCH_PER_REPLICA = 16\n",
    "SNN_LR = 3e-5\n",
    "ITERATE = False\n",
    "TIMESTEPS = 32\n",
    "DT = 1. # 1s\n",
    "DT_TARGET = .001  # 1ms\n",
    "L2 = 1e-9\n",
    "LOWER_HZ = 10\n",
    "UPPER_HZ = 20\n",
    "TAU = .1\n",
    "\n",
    "# - Augmentation parameters\n",
    "LOWER_ZOOM = .95\n",
    "UPPER_ZOOM = 1.05\n",
    "MAX_BRIGHTNESS_DELTA = .2\n",
    "MAX_HUE_DELTA = .1\n",
    "LOWER_CONTRAST = .2\n",
    "UPPER_CONTRAST = 1.8\n",
    "LOWER_SATURATION =.9\n",
    "UPPER_SATURATION = 1.1\n",
    "\n",
    "# - Save paths\n",
    "ANN_MODEL_PATH = 'ann_model.h5'\n",
    "SNN_MODELS_PATH = 'snn_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3f922",
   "metadata": {},
   "source": [
    "We also set up (multiple) GPU training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy parameters (for multiple GPU training)\n",
    "STRATEGY = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "NUM_DEVICES = STRATEGY.num_replicas_in_sync\n",
    "print('Number of devices: {}'.format(NUM_DEVICES))\n",
    "\n",
    "# Global batch sizes\n",
    "ANN_BATCH_SIZE = ANN_BATCH_PER_REPLICA * NUM_DEVICES\n",
    "SNN_BATCH_SIZE = SNN_BATCH_PER_REPLICA * NUM_DEVICES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d90dfe5",
   "metadata": {},
   "source": [
    "## Training a VGG16-based model on EuroSAT RGB and UC Merced datasets\n",
    "In the first part of the project we download either the [EuroSAT: Land Use and Land Cover Classification with Sentinel-2 Dataset](https://github.com/phelber/EuroSAT) (10 classes, 27000 examples) or the [UC Merced Land Use Dataset](http://weegee.vision.ucmerced.edu/datasets/landuse.html) (21 classes, 100 examples each). We slice it into the training, validation, and test sets using ratios 80%-10%-10%. We resize the [UC Merced](http://weegee.vision.ucmerced.edu/datasets/landuse.html) images\n",
    "to (224, 224, 3) shape (to be compatible with the usual [VGG-16](https://neurohive.io/en/popular-networks/vgg16/) input size). We augment the training set using random dihedral group transformation, random crop, random brightness change,  random contrast change, random hue change, random saturation change, as specified in the augmentation hyperparameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca24d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display samples\n",
    "download_name = 'uc_merced' if 'ucm' in DATASET else 'eurosat/rgb'\n",
    "ds, info = tfds.load(download_name, split='train', with_info=True)\n",
    "tfds.show_examples(ds, info)\n",
    "\n",
    "# Augmentation\n",
    "augmentation_parameters = {'lower_zoom': LOWER_ZOOM,\n",
    "                           'upper_zoom': UPPER_ZOOM,\n",
    "                           'max_brightness_delta': MAX_BRIGHTNESS_DELTA,\n",
    "                           'max_hue_delta': MAX_HUE_DELTA,\n",
    "                           'lower_contrast': LOWER_CONTRAST,\n",
    "                           'upper_contrast': UPPER_CONTRAST,\n",
    "                           'lower_saturation': LOWER_SATURATION,\n",
    "                           'upper_saturation': UPPER_SATURATION}\n",
    "\n",
    "# Load training, validation, and test data\n",
    "train, val, test, _ = load_data(dataset=DATASET,\n",
    "                                    input_size=INPUT_SHAPE[:-1],\n",
    "                                    augmentation_parameters=augmentation_parameters,\n",
    "                                    batch_size=ANN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2838237",
   "metadata": {},
   "source": [
    "We use a modified version of the [VGG-16](https://neurohive.io/en/popular-networks/vgg16/) network trained on the [ImageNet](http://www.image-net.org/) dataset (parameters from the [Keras-TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16)) version to construct a classifier for this dataset. We replace the max pooling layers with average pooling layers, we remove the head of the network (all the\n",
    "layers following the last pooling layers) and replace it with a global pooling layer, and a dense classifier without bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with STRATEGY.scope():\n",
    "    # - Create model\n",
    "    model = create_vgg16_model(input_shape=INPUT_SHAPE,\n",
    "                               kernel_l2=KERNEL_L2,\n",
    "                               bias_l1=BIAS_L1,\n",
    "                               num_classes=NUM_CLASSES,\n",
    "                               remove_pooling=False,\n",
    "                               use_dense_bias=False)\n",
    "\n",
    "    # -- Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(ANN_LR),\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=tf.metrics.SparseCategoricalAccuracy())\n",
    "\n",
    "# -- Show the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfede9a7",
   "metadata": {},
   "source": [
    "The model is trained using the RMSprop optimizer, using early stopping and reducing the learning rate on a plateau (by a factor of 10) if there is no significant improvement in the validation loss after 100 and 50 consecutive\n",
    "epochs respectively. Optionally, L<sub>2</sub> and L<sub>1</sub> regularization is applied to convolutional kernels and biases, respectively, if it was specified in the hyperparameters above. We save the best model to `ANN_MODEL_FILEPATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73355c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (OPTIONAL)\n",
    "# Callbacks                                                              \n",
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(verbose=True, patience=50),\n",
    "             tf.keras.callbacks.EarlyStopping(patience=100),\n",
    "             tf.keras.callbacks.ModelCheckpoint(filepath=ANN_MODEL_PATH, verbose=True, save_best_only=True)]\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x=train, epochs=ANN_EPOCHS, validation_data=val, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32d219",
   "metadata": {},
   "source": [
    "And finally, we evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45310f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best weights\n",
    "model.load_weights(ANN_MODEL_PATH)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(x=test)\n",
    "print(\"Best model's accuracy:\", colour_str(f'{acc:.2%}', 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2306ae9",
   "metadata": {},
   "source": [
    "## Training a spiking model\n",
    "\n",
    "A [VGG-16](https://neurohive.io/en/popular-networks/vgg16/) -based classifiertrained on the [EuroSat](https://github.com/phelber/EuroSAT) or [UC Merced](http://weegee.vision.ucmerced.edu/datasets/landuse.html) datasets can be converted into a spiking neural network and trained using [KerasSpiking](https://www.nengo.ai/keras-spiking/). Before the training, the local average pooling layers are removed, and the preceding convolutions have their strides set to 2, and their weights appropriately adjusted for  onsistency. The ReLU activation functions are swapped with [spiking activations](https://www.nengo.ai/keras-spiking/reference.html?highlight=spiking#keras_spiking.SpikingActivation) followed by a [low-pass filter](https://www.nengo.ai/keras-spiking/reference.html?highlight=spiking#keras_spiking.Lowpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e59bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with STRATEGY.scope():\n",
    "    # A variable to be passed to the model as the simulation time resolution\n",
    "    dt_var = tf.Variable(DT, aggregation=tf.VariableAggregation.MEAN)\n",
    "\n",
    "    # Functions to monitor the variables\n",
    "    def dt_monitor(y_true, y_pred):\n",
    "        return dt_var.read_value()\n",
    "\n",
    "    # Create a model\n",
    "    model = create_spiking_vgg16_model(model_path=ANN_MODEL_PATH,\n",
    "                                       input_shape=INPUT_SHAPE,\n",
    "                                       dt=dt_var,\n",
    "                                       l2=L2,\n",
    "                                       lower_hz=LOWER_HZ,\n",
    "                                       upper_hz=UPPER_HZ,\n",
    "                                       tau=TAU,\n",
    "                                       num_classes=NUM_CLASSES,\n",
    "                                       spiking_aware_training=True)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(SNN_LR),\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[tf.metrics.SparseCategoricalAccuracy(), dt_monitor])\n",
    "\n",
    "# Show model's summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9bc6a",
   "metadata": {},
   "source": [
    "Training can be performed iteratively, doubling the number of timesteps, and halving the batch size, the number of epochs, and the learning rate at each iteration. We also need to reload the data, since now they have a temporal dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1339e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponent = int(np.log2(TIMESTEPS))\n",
    "start = 0 if ITERATE else exponent\n",
    "for n in range(start, exponent + 1):\n",
    "    # Iterative hyperparameters\n",
    "    timesteps = 2 ** n\n",
    "    batch_size = 2 ** (exponent - n) * SNN_BATCH_SIZE\n",
    "    lr = SNN_LR * 2 ** (exponent - n)\n",
    "    tf.keras.backend.set_value(model.optimizer.learning_rate, lr)\n",
    "    epochs = SNN_EPOCHS * 2 ** (exponent - n)\n",
    "\n",
    "    # Load data\n",
    "    train, val, test, _ = load_data(DATASET,\n",
    "                                    input_size=INPUT_SHAPE[:-1],\n",
    "                                    augmentation_parameters=augmentation_parameters,\n",
    "                                    batch_size=batch_size,\n",
    "                                    timesteps=timesteps)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(patience=epochs // 4, verbose=True),\n",
    "                 tf.keras.callbacks.EarlyStopping(patience=epochs // 2, verbose=True)]\n",
    "\n",
    "    if dt_var.value() > DT_TARGET:\n",
    "        callbacks.append(DTStop(dt=dt_var, dt_min=DT_TARGET))\n",
    "\n",
    "    # Print the training iteration parameters\n",
    "    print(f\"Starting the training for {colour_str(epochs, 'orange')} epoch(s),\",\n",
    "          f\"with {colour_str(timesteps, 'orange')} timestep(s),\",\n",
    "          f\"on batches of {colour_str(batch_size, 'orange')} example(s),\",\n",
    "          f\"and the learning rate {colour_str(lr, 'orange')}.\")\n",
    "\n",
    "    # Train the model\n",
    "    print('Commencing the training on iteration',\n",
    "          colour_str(f'{n - start + 1}/{exponent + 1 - start}', 'orange') + '.')\n",
    "    model.fit(x=train, epochs=epochs, validation_data=val, callbacks=callbacks)\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(x=test, batch_size=batch_size, verbose=True)\n",
    "    try:\n",
    "        loss, acc, dt_stop = results\n",
    "    except ValueError:\n",
    "        loss, acc = results\n",
    "        dt_stop = DT_TARGET\n",
    "\n",
    "    print(\"Model's accuracy:\", colour_str(f'{acc:.2%}', 'green'))\n",
    "\n",
    "    # New model to avoid serialization issues\n",
    "    with STRATEGY.scope():\n",
    "        new_model = create_spiking_vgg16_model(model_path=ANN_MODEL_PATH,\n",
    "                                               input_shape=INPUT_SHAPE,\n",
    "                                               dt=dt_stop,\n",
    "                                               l2=L2,\n",
    "                                               lower_hz=LOWER_HZ,\n",
    "                                               upper_hz=UPPER_HZ,\n",
    "                                               tau=TAU,\n",
    "                                               num_classes=NUM_CLASSES,\n",
    "                                               spiking_aware_training=True)\n",
    "\n",
    "        # - Load weights (skipping dt)\n",
    "        new_model.set_weights([w for w in model.get_weights() if w.shape != ()])\n",
    "\n",
    "        # - Compile the model\n",
    "        new_model.compile(optimizer=tf.keras.optimizers.RMSprop(SNN_LR),\n",
    "                          loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    # Save model filepath\n",
    "    new_model.save(f\"{SNN_MODELS_PATH}/{n}.h5\")\n",
    "\n",
    "    # We stop optimising dt here\n",
    "    if dt_stop <= DT_TARGET:\n",
    "        model = new_model\n",
    "\n",
    "    del new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baad49",
   "metadata": {},
   "source": [
    "### Energy consumption estimation\n",
    "We can now compare the estimated energy consumption of the ANN and SNN (both with local pooling layers replaced by doubly-strided convolutions) on representative hardware (standard and neuromorphic). The value is estimated by considering the energy for a MAC operation. Such energy (`E_per_mac`) is obtained through a maximum-likelihood estimation: `E_inf = E_per_mac * N_ops`, after [G. Benelli, G. Meoni, and L. Fanucci, *Low power keyword spotting algorithm for memory constrained embedded systems*](https://ieeexplore.ieee.org/abstract/document/8644728). The particular values for standard hardware come from [B. Degnan, B. Marr, and J. Hasler, *Assessing Trends in Performance per Watt for Signal Processing Applications*](https://ieeexplore.ieee.org/abstract/document/7054508), the vallues for SpiNNaker come from [S. HÃ¶ppner, et al, *Dynamic Power Management for Neuromorphic Many-Core Systems*](https://ieeexplore.ieee.org/document/8701528), while the values for Loihi are from [M. Davies, et al, *Loihi: A Neuromorphic Manycore Processor with On-Chip Learning*](https://ieeexplore.ieee.org/document/8259423)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_synop_energy_dict, ann_neuron_energy_dict, ann_total_energy_dict = energy_estimation(model,\n",
    "                                                                                         spiking_model=False,\n",
    "                                                                                         verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b423eff",
   "metadata": {},
   "source": [
    "For the spiking energy estimation, we need to reload the test data (as the energy usage will depend on it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc24343",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test, info = load_data(dataset=DATASET,\n",
    "                             input_size=INPUT_SHAPE[:-1],\n",
    "                             batch_size=SNN_BATCH_SIZE,\n",
    "                             timesteps=TIMESTEPS)\n",
    "\n",
    "# Discard the labels to conserve the energy and have no inconsistencies in the synaptic energy estimation model\n",
    "xtest = test.map(lambda x, y: x, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c35797",
   "metadata": {},
   "source": [
    "And finally, we can estimate the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_synop_energy_dict, snn_neuron_energy_dict, snn_total_energy_dict = energy_estimation(model,\n",
    "                                                                                         x_test=test,\n",
    "                                                                                         spiking_model=True,\n",
    "                                                                                         device_list=['loihi',\n",
    "                                                                                                      'spinnaker',\n",
    "                                                                                                      'spinnaker2'],\n",
    "                                                                                         n_timesteps=TIMESTEPS,\n",
    "                                                                                         dt=dt_stop,\n",
    "                                                                                         verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
